{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd1e6a2a-c537-448d-b2b3-9a0d725f93d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b0c443-c53e-4ab5-880b-2f5426536e0a",
   "metadata": {},
   "source": [
    "Below I list the PEFT technique, the model, evaluation approach and fine-tunning dataset I'll be using to fine tune the LLM\n",
    "* PEFT technique: LoRA\n",
    "* Model: Llama 3.1 8B\n",
    "* Evaluation approach: Hugging Face Trainer.evaluate\n",
    "* Fine-tuning dataset: [AuthorMix](https://huggingface.co/datasets/hallisky/AuthorMix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a20aa8-1dda-4a38-a501-7b06fb61ed8d",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "Loading Llama 3.1 8B model and evaluate its performance prior to fine-tuning. This includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58143446-4483-4e1f-9e55-c54d719d01da",
   "metadata": {},
   "source": [
    "## Load in IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd388f79-cce5-4539-814d-10efe4a018cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q \"datasets>=2.16.1\"\n",
    "!pip install torch\n",
    "!pip install transformers==4.44.1\n",
    "!pip install python-dotenv\n",
    "!pip install peft\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8918ad8a-b8de-4a6c-87c6-1a2ad236fbba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['style', 'text', 'category'],\n",
       "     num_rows: 1000\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['style', 'text', 'category'],\n",
       "     num_rows: 1000\n",
       " })}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the train and test splits of the imdb dataset\n",
    "splits = [\"train\", \"test\"]\n",
    "ds = {\n",
    "    split: ds for split,\n",
    "    ds in zip(splits, load_dataset(\"hallisky/AuthorMix\", split=splits))\n",
    "}\n",
    "\n",
    "# Thin out the dataset to make it run faster for this example\n",
    "for split in splits:\n",
    "    ds[split] = ds[split].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "# Show the dataset\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6856202-59c2-455e-95ce-3f20ec749bde",
   "metadata": {},
   "source": [
    "### Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b0c14d-6f47-4031-ab63-f4b680484d44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       style                                               text category\n",
      "0  blog11518  \"Jamaia....come and help me talk some sense in...     blog\n",
      "1  blog25872  I decided I wasn't going to go to Boler today....     blog\n",
      "2      obama  For over two decades, bin Laden has been al Qa...   speech\n",
      "3  blog11518  motion with precise timing. Sucking the cigare...     blog\n",
      "4  blog11518  \"So what, we just stand here?\" Alyx prompts, h...     blog\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame(ds['train'])\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b723df4a-f77c-481f-a4c3-46aab12ee804",
   "metadata": {},
   "source": [
    "The dataset contains 14 unique authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55da3da0-d383-4102-a38c-3d642689d940",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blog11518' 'blog25872' 'obama' 'fitzgerald' 'hemingway' 'woolf' 'bush'\n",
      " 'blog30102' 'blog5546' 'trump' 'blog30407' 'qq' 'pp' 'h']\n"
     ]
    }
   ],
   "source": [
    "unique_styles = train_df['style'].unique()\n",
    "print(unique_styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a140e13c-516d-49c6-b1be-2cc84f858800",
   "metadata": {},
   "source": [
    "In 4 number of formats/categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "099a092b-1450-4499-a5c8-345a5b40c8c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blog' 'speech' 'author' 'amt']\n"
     ]
    }
   ],
   "source": [
    "unique_formats = train_df['category'].unique()\n",
    "print(unique_formats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9d27df-5594-4981-b4bc-e13cb280c6b8",
   "metadata": {},
   "source": [
    "Dataset sample text length just skew towards 335 characters or less "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a869c4b-ac04-40f6-9e0e-4c4a89d805fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_df['text_length'] = train_df['text'].str.len()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train_df['text_length'], bins=30, edgecolor='black')\n",
    "plt.title('Distribution of Text Lengths')\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eafac08-a712-4ede-b84b-d4e16b473877",
   "metadata": {},
   "source": [
    "### Intial Llama 3.1 8B/GPT-2 evaluation on the dataset\n",
    "Going to load in the Llama/GPT-2 model through AutoModelForSequenceClassification and set the label ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8363fe2a-97b2-43eb-9dcb-8430e7cab142",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/david/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv(\"env.txt\")\n",
    "hf_token = os.getenv('HF_API_TOKEN')\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "945e0a85-1e77-4f16-9e5b-439d558fd8ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_labels: 14\n",
      "id2label: {0: 'blog11518', 1: 'blog25872', 2: 'obama', 3: 'fitzgerald', 4: 'hemingway', 5: 'woolf', 6: 'bush', 7: 'blog30102', 8: 'blog5546', 9: 'trump', 10: 'blog30407', 11: 'qq', 12: 'pp', 13: 'h'}\n",
      "label2id: {'blog11518': 0, 'blog25872': 1, 'obama': 2, 'fitzgerald': 3, 'hemingway': 4, 'woolf': 5, 'bush': 6, 'blog30102': 7, 'blog5546': 8, 'trump': 9, 'blog30407': 10, 'qq': 11, 'pp': 12, 'h': 13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d83c57653848b088fc6e82c06067e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3.1-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "num_labels = len(unique_styles)\n",
    "id2label = {i: style for i, style in enumerate(unique_styles)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "print(f\"num_labels: {num_labels}\")\n",
    "print(f\"id2label: {id2label}\")\n",
    "print(f\"label2id: {label2id}\")\n",
    "llama_model_key = \"meta-llama/Meta-Llama-3.1-8B\"\n",
    "gpt_model_key = \"openai-community/gpt2\"\n",
    "gpt_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    gpt_model_key,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    token=True,\n",
    ")\n",
    "llama_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    llama_model_key,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    token=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0984e7e6-b9b3-46b5-8f86-570d30b4ef89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer setup\n",
    "# GPT\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained(gpt_model_key, token=True)\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "gpt_model.config.pad_token_id = gpt_tokenizer.pad_token_id\n",
    "\n",
    "#llama\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(llama_model_key, token=True)\n",
    "llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "llama_model.config.pad_token_id = llama_tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "653edbc2-728f-46d5-9d14-8b3c03fe1d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(model, text, tokenizer):\n",
    "    # Ensure the text is correctly passed as a string\n",
    "    if not isinstance(text, str):\n",
    "        raise ValueError(\"Input text must be a string\")\n",
    "\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "\n",
    "    # Perform the prediction (get the logits)\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Get the predicted class (assuming this is for classification)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = logits.argmax(dim=-1)\n",
    "\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0dcbdde-f0b5-4f01-862b-21818900e8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'style': 'woolf',\n",
       " 'text': '\"It\\'s his way of making friends, I suppose,\" she laughed. \"Well--I shall do my part. I shall begin--\\'Ugly in body, repulsive in mind as you are, Mr. Hirst--\\'\"',\n",
       " 'category': 'author'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['test'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f05ebc89-7a46-44e5-baca-65bdddd2da19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = get_prediction(llama_model, ds['test'][15]['text'], llama_tokenizer)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c78c3b88-9a09-4331-a2a1-051cbb091a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def evaluate_model(dataset, model, tokenizer, n=10):\n",
    "    correct_predictions = 0\n",
    "\n",
    "    # Iterate over the first 'n' samples of the dataset\n",
    "    for i in range(n):\n",
    "        # Get the input text and true label from the dataset\n",
    "        text = dataset['test'][i]['text']\n",
    "        true_label = dataset['test'][i]['style']  # Assuming 'style' is the label field\n",
    "\n",
    "        # If the text is not a string, join it into a string\n",
    "        if isinstance(text, list):\n",
    "            text = \" \".join(text)\n",
    "\n",
    "        # Get the model's prediction\n",
    "        predicted_class = get_prediction(model, text, tokenizer)\n",
    "\n",
    "        # Check if the prediction is correct\n",
    "        if predicted_class.item() == label2id[true_label]:  # Convert tensor to scalar with .item()\n",
    "            correct_predictions += 1\n",
    "\n",
    "    # Return the accuracy of the model on 'n' samples\n",
    "    accuracy = correct_predictions / n\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32218169-b5d1-4511-a8be-0e2e2a1093db",
   "metadata": {},
   "source": [
    "### Llama Pre-Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e4677df-46c5-420f-b436-4bcb2dbc5d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(ds, model=llama_model, tokenizer=llama_tokenizer, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c653f8-d751-4274-afd3-c8c86e5caca0",
   "metadata": {},
   "source": [
    "### GPT Pre-Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cc73d4d-2a3b-4c3d-8786-f59a83499447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(ds, model=gpt_model, tokenizer=gpt_tokenizer, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b02d83d-3cf8-4e4d-b21b-579897320b93",
   "metadata": {},
   "source": [
    "### Setup PEFT Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73145267-1c5f-4a7b-8c74-afdfd2713e60",
   "metadata": {},
   "source": [
    "#### Get modules to target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ecb58e5-a9e5-4af5-84b4-916a9b90204f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "transformer\n",
      "transformer.wte\n",
      "transformer.wpe\n",
      "transformer.drop\n",
      "transformer.h\n",
      "transformer.h.0\n",
      "transformer.h.0.ln_1\n",
      "transformer.h.0.attn\n",
      "transformer.h.0.attn.c_attn\n",
      "transformer.h.0.attn.c_proj\n",
      "transformer.h.0.attn.attn_dropout\n",
      "transformer.h.0.attn.resid_dropout\n",
      "transformer.h.0.ln_2\n",
      "transformer.h.0.mlp\n",
      "transformer.h.0.mlp.c_fc\n",
      "transformer.h.0.mlp.c_proj\n",
      "transformer.h.0.mlp.act\n",
      "transformer.h.0.mlp.dropout\n",
      "transformer.h.1\n",
      "transformer.h.1.ln_1\n",
      "transformer.h.1.attn\n",
      "transformer.h.1.attn.c_attn\n",
      "transformer.h.1.attn.c_proj\n",
      "transformer.h.1.attn.attn_dropout\n",
      "transformer.h.1.attn.resid_dropout\n",
      "transformer.h.1.ln_2\n",
      "transformer.h.1.mlp\n",
      "transformer.h.1.mlp.c_fc\n",
      "transformer.h.1.mlp.c_proj\n",
      "transformer.h.1.mlp.act\n",
      "transformer.h.1.mlp.dropout\n",
      "transformer.h.2\n",
      "transformer.h.2.ln_1\n",
      "transformer.h.2.attn\n",
      "transformer.h.2.attn.c_attn\n",
      "transformer.h.2.attn.c_proj\n",
      "transformer.h.2.attn.attn_dropout\n",
      "transformer.h.2.attn.resid_dropout\n",
      "transformer.h.2.ln_2\n",
      "transformer.h.2.mlp\n",
      "transformer.h.2.mlp.c_fc\n",
      "transformer.h.2.mlp.c_proj\n",
      "transformer.h.2.mlp.act\n",
      "transformer.h.2.mlp.dropout\n",
      "transformer.h.3\n",
      "transformer.h.3.ln_1\n",
      "transformer.h.3.attn\n",
      "transformer.h.3.attn.c_attn\n",
      "transformer.h.3.attn.c_proj\n",
      "transformer.h.3.attn.attn_dropout\n",
      "transformer.h.3.attn.resid_dropout\n",
      "transformer.h.3.ln_2\n",
      "transformer.h.3.mlp\n",
      "transformer.h.3.mlp.c_fc\n",
      "transformer.h.3.mlp.c_proj\n",
      "transformer.h.3.mlp.act\n",
      "transformer.h.3.mlp.dropout\n",
      "transformer.h.4\n",
      "transformer.h.4.ln_1\n",
      "transformer.h.4.attn\n",
      "transformer.h.4.attn.c_attn\n",
      "transformer.h.4.attn.c_proj\n",
      "transformer.h.4.attn.attn_dropout\n",
      "transformer.h.4.attn.resid_dropout\n",
      "transformer.h.4.ln_2\n",
      "transformer.h.4.mlp\n",
      "transformer.h.4.mlp.c_fc\n",
      "transformer.h.4.mlp.c_proj\n",
      "transformer.h.4.mlp.act\n",
      "transformer.h.4.mlp.dropout\n",
      "transformer.h.5\n",
      "transformer.h.5.ln_1\n",
      "transformer.h.5.attn\n",
      "transformer.h.5.attn.c_attn\n",
      "transformer.h.5.attn.c_proj\n",
      "transformer.h.5.attn.attn_dropout\n",
      "transformer.h.5.attn.resid_dropout\n",
      "transformer.h.5.ln_2\n",
      "transformer.h.5.mlp\n",
      "transformer.h.5.mlp.c_fc\n",
      "transformer.h.5.mlp.c_proj\n",
      "transformer.h.5.mlp.act\n",
      "transformer.h.5.mlp.dropout\n",
      "transformer.h.6\n",
      "transformer.h.6.ln_1\n",
      "transformer.h.6.attn\n",
      "transformer.h.6.attn.c_attn\n",
      "transformer.h.6.attn.c_proj\n",
      "transformer.h.6.attn.attn_dropout\n",
      "transformer.h.6.attn.resid_dropout\n",
      "transformer.h.6.ln_2\n",
      "transformer.h.6.mlp\n",
      "transformer.h.6.mlp.c_fc\n",
      "transformer.h.6.mlp.c_proj\n",
      "transformer.h.6.mlp.act\n",
      "transformer.h.6.mlp.dropout\n",
      "transformer.h.7\n",
      "transformer.h.7.ln_1\n",
      "transformer.h.7.attn\n",
      "transformer.h.7.attn.c_attn\n",
      "transformer.h.7.attn.c_proj\n",
      "transformer.h.7.attn.attn_dropout\n",
      "transformer.h.7.attn.resid_dropout\n",
      "transformer.h.7.ln_2\n",
      "transformer.h.7.mlp\n",
      "transformer.h.7.mlp.c_fc\n",
      "transformer.h.7.mlp.c_proj\n",
      "transformer.h.7.mlp.act\n",
      "transformer.h.7.mlp.dropout\n",
      "transformer.h.8\n",
      "transformer.h.8.ln_1\n",
      "transformer.h.8.attn\n",
      "transformer.h.8.attn.c_attn\n",
      "transformer.h.8.attn.c_proj\n",
      "transformer.h.8.attn.attn_dropout\n",
      "transformer.h.8.attn.resid_dropout\n",
      "transformer.h.8.ln_2\n",
      "transformer.h.8.mlp\n",
      "transformer.h.8.mlp.c_fc\n",
      "transformer.h.8.mlp.c_proj\n",
      "transformer.h.8.mlp.act\n",
      "transformer.h.8.mlp.dropout\n",
      "transformer.h.9\n",
      "transformer.h.9.ln_1\n",
      "transformer.h.9.attn\n",
      "transformer.h.9.attn.c_attn\n",
      "transformer.h.9.attn.c_proj\n",
      "transformer.h.9.attn.attn_dropout\n",
      "transformer.h.9.attn.resid_dropout\n",
      "transformer.h.9.ln_2\n",
      "transformer.h.9.mlp\n",
      "transformer.h.9.mlp.c_fc\n",
      "transformer.h.9.mlp.c_proj\n",
      "transformer.h.9.mlp.act\n",
      "transformer.h.9.mlp.dropout\n",
      "transformer.h.10\n",
      "transformer.h.10.ln_1\n",
      "transformer.h.10.attn\n",
      "transformer.h.10.attn.c_attn\n",
      "transformer.h.10.attn.c_proj\n",
      "transformer.h.10.attn.attn_dropout\n",
      "transformer.h.10.attn.resid_dropout\n",
      "transformer.h.10.ln_2\n",
      "transformer.h.10.mlp\n",
      "transformer.h.10.mlp.c_fc\n",
      "transformer.h.10.mlp.c_proj\n",
      "transformer.h.10.mlp.act\n",
      "transformer.h.10.mlp.dropout\n",
      "transformer.h.11\n",
      "transformer.h.11.ln_1\n",
      "transformer.h.11.attn\n",
      "transformer.h.11.attn.c_attn\n",
      "transformer.h.11.attn.c_proj\n",
      "transformer.h.11.attn.attn_dropout\n",
      "transformer.h.11.attn.resid_dropout\n",
      "transformer.h.11.ln_2\n",
      "transformer.h.11.mlp\n",
      "transformer.h.11.mlp.c_fc\n",
      "transformer.h.11.mlp.c_proj\n",
      "transformer.h.11.mlp.act\n",
      "transformer.h.11.mlp.dropout\n",
      "transformer.ln_f\n",
      "score\n"
     ]
    }
   ],
   "source": [
    "for name, module in gpt_model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03fb39f1-e1a7-4b31-ad2e-ac2379a6f407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model\n",
      "model.embed_tokens\n",
      "model.layers\n",
      "model.layers.0\n",
      "model.layers.0.self_attn\n",
      "model.layers.0.self_attn.q_proj\n",
      "model.layers.0.self_attn.k_proj\n",
      "model.layers.0.self_attn.v_proj\n",
      "model.layers.0.self_attn.o_proj\n",
      "model.layers.0.self_attn.rotary_emb\n",
      "model.layers.0.mlp\n",
      "model.layers.0.mlp.gate_proj\n",
      "model.layers.0.mlp.up_proj\n",
      "model.layers.0.mlp.down_proj\n",
      "model.layers.0.mlp.act_fn\n",
      "model.layers.0.input_layernorm\n",
      "model.layers.0.post_attention_layernorm\n",
      "model.layers.1\n",
      "model.layers.1.self_attn\n",
      "model.layers.1.self_attn.q_proj\n",
      "model.layers.1.self_attn.k_proj\n",
      "model.layers.1.self_attn.v_proj\n",
      "model.layers.1.self_attn.o_proj\n",
      "model.layers.1.self_attn.rotary_emb\n",
      "model.layers.1.mlp\n",
      "model.layers.1.mlp.gate_proj\n",
      "model.layers.1.mlp.up_proj\n",
      "model.layers.1.mlp.down_proj\n",
      "model.layers.1.mlp.act_fn\n",
      "model.layers.1.input_layernorm\n",
      "model.layers.1.post_attention_layernorm\n",
      "model.layers.2\n",
      "model.layers.2.self_attn\n",
      "model.layers.2.self_attn.q_proj\n",
      "model.layers.2.self_attn.k_proj\n",
      "model.layers.2.self_attn.v_proj\n",
      "model.layers.2.self_attn.o_proj\n",
      "model.layers.2.self_attn.rotary_emb\n",
      "model.layers.2.mlp\n",
      "model.layers.2.mlp.gate_proj\n",
      "model.layers.2.mlp.up_proj\n",
      "model.layers.2.mlp.down_proj\n",
      "model.layers.2.mlp.act_fn\n",
      "model.layers.2.input_layernorm\n",
      "model.layers.2.post_attention_layernorm\n",
      "model.layers.3\n",
      "model.layers.3.self_attn\n",
      "model.layers.3.self_attn.q_proj\n",
      "model.layers.3.self_attn.k_proj\n",
      "model.layers.3.self_attn.v_proj\n",
      "model.layers.3.self_attn.o_proj\n",
      "model.layers.3.self_attn.rotary_emb\n",
      "model.layers.3.mlp\n",
      "model.layers.3.mlp.gate_proj\n",
      "model.layers.3.mlp.up_proj\n",
      "model.layers.3.mlp.down_proj\n",
      "model.layers.3.mlp.act_fn\n",
      "model.layers.3.input_layernorm\n",
      "model.layers.3.post_attention_layernorm\n",
      "model.layers.4\n",
      "model.layers.4.self_attn\n",
      "model.layers.4.self_attn.q_proj\n",
      "model.layers.4.self_attn.k_proj\n",
      "model.layers.4.self_attn.v_proj\n",
      "model.layers.4.self_attn.o_proj\n",
      "model.layers.4.self_attn.rotary_emb\n",
      "model.layers.4.mlp\n",
      "model.layers.4.mlp.gate_proj\n",
      "model.layers.4.mlp.up_proj\n",
      "model.layers.4.mlp.down_proj\n",
      "model.layers.4.mlp.act_fn\n",
      "model.layers.4.input_layernorm\n",
      "model.layers.4.post_attention_layernorm\n",
      "model.layers.5\n",
      "model.layers.5.self_attn\n",
      "model.layers.5.self_attn.q_proj\n",
      "model.layers.5.self_attn.k_proj\n",
      "model.layers.5.self_attn.v_proj\n",
      "model.layers.5.self_attn.o_proj\n",
      "model.layers.5.self_attn.rotary_emb\n",
      "model.layers.5.mlp\n",
      "model.layers.5.mlp.gate_proj\n",
      "model.layers.5.mlp.up_proj\n",
      "model.layers.5.mlp.down_proj\n",
      "model.layers.5.mlp.act_fn\n",
      "model.layers.5.input_layernorm\n",
      "model.layers.5.post_attention_layernorm\n",
      "model.layers.6\n",
      "model.layers.6.self_attn\n",
      "model.layers.6.self_attn.q_proj\n",
      "model.layers.6.self_attn.k_proj\n",
      "model.layers.6.self_attn.v_proj\n",
      "model.layers.6.self_attn.o_proj\n",
      "model.layers.6.self_attn.rotary_emb\n",
      "model.layers.6.mlp\n",
      "model.layers.6.mlp.gate_proj\n",
      "model.layers.6.mlp.up_proj\n",
      "model.layers.6.mlp.down_proj\n",
      "model.layers.6.mlp.act_fn\n",
      "model.layers.6.input_layernorm\n",
      "model.layers.6.post_attention_layernorm\n",
      "model.layers.7\n",
      "model.layers.7.self_attn\n",
      "model.layers.7.self_attn.q_proj\n",
      "model.layers.7.self_attn.k_proj\n",
      "model.layers.7.self_attn.v_proj\n",
      "model.layers.7.self_attn.o_proj\n",
      "model.layers.7.self_attn.rotary_emb\n",
      "model.layers.7.mlp\n",
      "model.layers.7.mlp.gate_proj\n",
      "model.layers.7.mlp.up_proj\n",
      "model.layers.7.mlp.down_proj\n",
      "model.layers.7.mlp.act_fn\n",
      "model.layers.7.input_layernorm\n",
      "model.layers.7.post_attention_layernorm\n",
      "model.layers.8\n",
      "model.layers.8.self_attn\n",
      "model.layers.8.self_attn.q_proj\n",
      "model.layers.8.self_attn.k_proj\n",
      "model.layers.8.self_attn.v_proj\n",
      "model.layers.8.self_attn.o_proj\n",
      "model.layers.8.self_attn.rotary_emb\n",
      "model.layers.8.mlp\n",
      "model.layers.8.mlp.gate_proj\n",
      "model.layers.8.mlp.up_proj\n",
      "model.layers.8.mlp.down_proj\n",
      "model.layers.8.mlp.act_fn\n",
      "model.layers.8.input_layernorm\n",
      "model.layers.8.post_attention_layernorm\n",
      "model.layers.9\n",
      "model.layers.9.self_attn\n",
      "model.layers.9.self_attn.q_proj\n",
      "model.layers.9.self_attn.k_proj\n",
      "model.layers.9.self_attn.v_proj\n",
      "model.layers.9.self_attn.o_proj\n",
      "model.layers.9.self_attn.rotary_emb\n",
      "model.layers.9.mlp\n",
      "model.layers.9.mlp.gate_proj\n",
      "model.layers.9.mlp.up_proj\n",
      "model.layers.9.mlp.down_proj\n",
      "model.layers.9.mlp.act_fn\n",
      "model.layers.9.input_layernorm\n",
      "model.layers.9.post_attention_layernorm\n",
      "model.layers.10\n",
      "model.layers.10.self_attn\n",
      "model.layers.10.self_attn.q_proj\n",
      "model.layers.10.self_attn.k_proj\n",
      "model.layers.10.self_attn.v_proj\n",
      "model.layers.10.self_attn.o_proj\n",
      "model.layers.10.self_attn.rotary_emb\n",
      "model.layers.10.mlp\n",
      "model.layers.10.mlp.gate_proj\n",
      "model.layers.10.mlp.up_proj\n",
      "model.layers.10.mlp.down_proj\n",
      "model.layers.10.mlp.act_fn\n",
      "model.layers.10.input_layernorm\n",
      "model.layers.10.post_attention_layernorm\n",
      "model.layers.11\n",
      "model.layers.11.self_attn\n",
      "model.layers.11.self_attn.q_proj\n",
      "model.layers.11.self_attn.k_proj\n",
      "model.layers.11.self_attn.v_proj\n",
      "model.layers.11.self_attn.o_proj\n",
      "model.layers.11.self_attn.rotary_emb\n",
      "model.layers.11.mlp\n",
      "model.layers.11.mlp.gate_proj\n",
      "model.layers.11.mlp.up_proj\n",
      "model.layers.11.mlp.down_proj\n",
      "model.layers.11.mlp.act_fn\n",
      "model.layers.11.input_layernorm\n",
      "model.layers.11.post_attention_layernorm\n",
      "model.layers.12\n",
      "model.layers.12.self_attn\n",
      "model.layers.12.self_attn.q_proj\n",
      "model.layers.12.self_attn.k_proj\n",
      "model.layers.12.self_attn.v_proj\n",
      "model.layers.12.self_attn.o_proj\n",
      "model.layers.12.self_attn.rotary_emb\n",
      "model.layers.12.mlp\n",
      "model.layers.12.mlp.gate_proj\n",
      "model.layers.12.mlp.up_proj\n",
      "model.layers.12.mlp.down_proj\n",
      "model.layers.12.mlp.act_fn\n",
      "model.layers.12.input_layernorm\n",
      "model.layers.12.post_attention_layernorm\n",
      "model.layers.13\n",
      "model.layers.13.self_attn\n",
      "model.layers.13.self_attn.q_proj\n",
      "model.layers.13.self_attn.k_proj\n",
      "model.layers.13.self_attn.v_proj\n",
      "model.layers.13.self_attn.o_proj\n",
      "model.layers.13.self_attn.rotary_emb\n",
      "model.layers.13.mlp\n",
      "model.layers.13.mlp.gate_proj\n",
      "model.layers.13.mlp.up_proj\n",
      "model.layers.13.mlp.down_proj\n",
      "model.layers.13.mlp.act_fn\n",
      "model.layers.13.input_layernorm\n",
      "model.layers.13.post_attention_layernorm\n",
      "model.layers.14\n",
      "model.layers.14.self_attn\n",
      "model.layers.14.self_attn.q_proj\n",
      "model.layers.14.self_attn.k_proj\n",
      "model.layers.14.self_attn.v_proj\n",
      "model.layers.14.self_attn.o_proj\n",
      "model.layers.14.self_attn.rotary_emb\n",
      "model.layers.14.mlp\n",
      "model.layers.14.mlp.gate_proj\n",
      "model.layers.14.mlp.up_proj\n",
      "model.layers.14.mlp.down_proj\n",
      "model.layers.14.mlp.act_fn\n",
      "model.layers.14.input_layernorm\n",
      "model.layers.14.post_attention_layernorm\n",
      "model.layers.15\n",
      "model.layers.15.self_attn\n",
      "model.layers.15.self_attn.q_proj\n",
      "model.layers.15.self_attn.k_proj\n",
      "model.layers.15.self_attn.v_proj\n",
      "model.layers.15.self_attn.o_proj\n",
      "model.layers.15.self_attn.rotary_emb\n",
      "model.layers.15.mlp\n",
      "model.layers.15.mlp.gate_proj\n",
      "model.layers.15.mlp.up_proj\n",
      "model.layers.15.mlp.down_proj\n",
      "model.layers.15.mlp.act_fn\n",
      "model.layers.15.input_layernorm\n",
      "model.layers.15.post_attention_layernorm\n",
      "model.layers.16\n",
      "model.layers.16.self_attn\n",
      "model.layers.16.self_attn.q_proj\n",
      "model.layers.16.self_attn.k_proj\n",
      "model.layers.16.self_attn.v_proj\n",
      "model.layers.16.self_attn.o_proj\n",
      "model.layers.16.self_attn.rotary_emb\n",
      "model.layers.16.mlp\n",
      "model.layers.16.mlp.gate_proj\n",
      "model.layers.16.mlp.up_proj\n",
      "model.layers.16.mlp.down_proj\n",
      "model.layers.16.mlp.act_fn\n",
      "model.layers.16.input_layernorm\n",
      "model.layers.16.post_attention_layernorm\n",
      "model.layers.17\n",
      "model.layers.17.self_attn\n",
      "model.layers.17.self_attn.q_proj\n",
      "model.layers.17.self_attn.k_proj\n",
      "model.layers.17.self_attn.v_proj\n",
      "model.layers.17.self_attn.o_proj\n",
      "model.layers.17.self_attn.rotary_emb\n",
      "model.layers.17.mlp\n",
      "model.layers.17.mlp.gate_proj\n",
      "model.layers.17.mlp.up_proj\n",
      "model.layers.17.mlp.down_proj\n",
      "model.layers.17.mlp.act_fn\n",
      "model.layers.17.input_layernorm\n",
      "model.layers.17.post_attention_layernorm\n",
      "model.layers.18\n",
      "model.layers.18.self_attn\n",
      "model.layers.18.self_attn.q_proj\n",
      "model.layers.18.self_attn.k_proj\n",
      "model.layers.18.self_attn.v_proj\n",
      "model.layers.18.self_attn.o_proj\n",
      "model.layers.18.self_attn.rotary_emb\n",
      "model.layers.18.mlp\n",
      "model.layers.18.mlp.gate_proj\n",
      "model.layers.18.mlp.up_proj\n",
      "model.layers.18.mlp.down_proj\n",
      "model.layers.18.mlp.act_fn\n",
      "model.layers.18.input_layernorm\n",
      "model.layers.18.post_attention_layernorm\n",
      "model.layers.19\n",
      "model.layers.19.self_attn\n",
      "model.layers.19.self_attn.q_proj\n",
      "model.layers.19.self_attn.k_proj\n",
      "model.layers.19.self_attn.v_proj\n",
      "model.layers.19.self_attn.o_proj\n",
      "model.layers.19.self_attn.rotary_emb\n",
      "model.layers.19.mlp\n",
      "model.layers.19.mlp.gate_proj\n",
      "model.layers.19.mlp.up_proj\n",
      "model.layers.19.mlp.down_proj\n",
      "model.layers.19.mlp.act_fn\n",
      "model.layers.19.input_layernorm\n",
      "model.layers.19.post_attention_layernorm\n",
      "model.layers.20\n",
      "model.layers.20.self_attn\n",
      "model.layers.20.self_attn.q_proj\n",
      "model.layers.20.self_attn.k_proj\n",
      "model.layers.20.self_attn.v_proj\n",
      "model.layers.20.self_attn.o_proj\n",
      "model.layers.20.self_attn.rotary_emb\n",
      "model.layers.20.mlp\n",
      "model.layers.20.mlp.gate_proj\n",
      "model.layers.20.mlp.up_proj\n",
      "model.layers.20.mlp.down_proj\n",
      "model.layers.20.mlp.act_fn\n",
      "model.layers.20.input_layernorm\n",
      "model.layers.20.post_attention_layernorm\n",
      "model.layers.21\n",
      "model.layers.21.self_attn\n",
      "model.layers.21.self_attn.q_proj\n",
      "model.layers.21.self_attn.k_proj\n",
      "model.layers.21.self_attn.v_proj\n",
      "model.layers.21.self_attn.o_proj\n",
      "model.layers.21.self_attn.rotary_emb\n",
      "model.layers.21.mlp\n",
      "model.layers.21.mlp.gate_proj\n",
      "model.layers.21.mlp.up_proj\n",
      "model.layers.21.mlp.down_proj\n",
      "model.layers.21.mlp.act_fn\n",
      "model.layers.21.input_layernorm\n",
      "model.layers.21.post_attention_layernorm\n",
      "model.layers.22\n",
      "model.layers.22.self_attn\n",
      "model.layers.22.self_attn.q_proj\n",
      "model.layers.22.self_attn.k_proj\n",
      "model.layers.22.self_attn.v_proj\n",
      "model.layers.22.self_attn.o_proj\n",
      "model.layers.22.self_attn.rotary_emb\n",
      "model.layers.22.mlp\n",
      "model.layers.22.mlp.gate_proj\n",
      "model.layers.22.mlp.up_proj\n",
      "model.layers.22.mlp.down_proj\n",
      "model.layers.22.mlp.act_fn\n",
      "model.layers.22.input_layernorm\n",
      "model.layers.22.post_attention_layernorm\n",
      "model.layers.23\n",
      "model.layers.23.self_attn\n",
      "model.layers.23.self_attn.q_proj\n",
      "model.layers.23.self_attn.k_proj\n",
      "model.layers.23.self_attn.v_proj\n",
      "model.layers.23.self_attn.o_proj\n",
      "model.layers.23.self_attn.rotary_emb\n",
      "model.layers.23.mlp\n",
      "model.layers.23.mlp.gate_proj\n",
      "model.layers.23.mlp.up_proj\n",
      "model.layers.23.mlp.down_proj\n",
      "model.layers.23.mlp.act_fn\n",
      "model.layers.23.input_layernorm\n",
      "model.layers.23.post_attention_layernorm\n",
      "model.layers.24\n",
      "model.layers.24.self_attn\n",
      "model.layers.24.self_attn.q_proj\n",
      "model.layers.24.self_attn.k_proj\n",
      "model.layers.24.self_attn.v_proj\n",
      "model.layers.24.self_attn.o_proj\n",
      "model.layers.24.self_attn.rotary_emb\n",
      "model.layers.24.mlp\n",
      "model.layers.24.mlp.gate_proj\n",
      "model.layers.24.mlp.up_proj\n",
      "model.layers.24.mlp.down_proj\n",
      "model.layers.24.mlp.act_fn\n",
      "model.layers.24.input_layernorm\n",
      "model.layers.24.post_attention_layernorm\n",
      "model.layers.25\n",
      "model.layers.25.self_attn\n",
      "model.layers.25.self_attn.q_proj\n",
      "model.layers.25.self_attn.k_proj\n",
      "model.layers.25.self_attn.v_proj\n",
      "model.layers.25.self_attn.o_proj\n",
      "model.layers.25.self_attn.rotary_emb\n",
      "model.layers.25.mlp\n",
      "model.layers.25.mlp.gate_proj\n",
      "model.layers.25.mlp.up_proj\n",
      "model.layers.25.mlp.down_proj\n",
      "model.layers.25.mlp.act_fn\n",
      "model.layers.25.input_layernorm\n",
      "model.layers.25.post_attention_layernorm\n",
      "model.layers.26\n",
      "model.layers.26.self_attn\n",
      "model.layers.26.self_attn.q_proj\n",
      "model.layers.26.self_attn.k_proj\n",
      "model.layers.26.self_attn.v_proj\n",
      "model.layers.26.self_attn.o_proj\n",
      "model.layers.26.self_attn.rotary_emb\n",
      "model.layers.26.mlp\n",
      "model.layers.26.mlp.gate_proj\n",
      "model.layers.26.mlp.up_proj\n",
      "model.layers.26.mlp.down_proj\n",
      "model.layers.26.mlp.act_fn\n",
      "model.layers.26.input_layernorm\n",
      "model.layers.26.post_attention_layernorm\n",
      "model.layers.27\n",
      "model.layers.27.self_attn\n",
      "model.layers.27.self_attn.q_proj\n",
      "model.layers.27.self_attn.k_proj\n",
      "model.layers.27.self_attn.v_proj\n",
      "model.layers.27.self_attn.o_proj\n",
      "model.layers.27.self_attn.rotary_emb\n",
      "model.layers.27.mlp\n",
      "model.layers.27.mlp.gate_proj\n",
      "model.layers.27.mlp.up_proj\n",
      "model.layers.27.mlp.down_proj\n",
      "model.layers.27.mlp.act_fn\n",
      "model.layers.27.input_layernorm\n",
      "model.layers.27.post_attention_layernorm\n",
      "model.layers.28\n",
      "model.layers.28.self_attn\n",
      "model.layers.28.self_attn.q_proj\n",
      "model.layers.28.self_attn.k_proj\n",
      "model.layers.28.self_attn.v_proj\n",
      "model.layers.28.self_attn.o_proj\n",
      "model.layers.28.self_attn.rotary_emb\n",
      "model.layers.28.mlp\n",
      "model.layers.28.mlp.gate_proj\n",
      "model.layers.28.mlp.up_proj\n",
      "model.layers.28.mlp.down_proj\n",
      "model.layers.28.mlp.act_fn\n",
      "model.layers.28.input_layernorm\n",
      "model.layers.28.post_attention_layernorm\n",
      "model.layers.29\n",
      "model.layers.29.self_attn\n",
      "model.layers.29.self_attn.q_proj\n",
      "model.layers.29.self_attn.k_proj\n",
      "model.layers.29.self_attn.v_proj\n",
      "model.layers.29.self_attn.o_proj\n",
      "model.layers.29.self_attn.rotary_emb\n",
      "model.layers.29.mlp\n",
      "model.layers.29.mlp.gate_proj\n",
      "model.layers.29.mlp.up_proj\n",
      "model.layers.29.mlp.down_proj\n",
      "model.layers.29.mlp.act_fn\n",
      "model.layers.29.input_layernorm\n",
      "model.layers.29.post_attention_layernorm\n",
      "model.layers.30\n",
      "model.layers.30.self_attn\n",
      "model.layers.30.self_attn.q_proj\n",
      "model.layers.30.self_attn.k_proj\n",
      "model.layers.30.self_attn.v_proj\n",
      "model.layers.30.self_attn.o_proj\n",
      "model.layers.30.self_attn.rotary_emb\n",
      "model.layers.30.mlp\n",
      "model.layers.30.mlp.gate_proj\n",
      "model.layers.30.mlp.up_proj\n",
      "model.layers.30.mlp.down_proj\n",
      "model.layers.30.mlp.act_fn\n",
      "model.layers.30.input_layernorm\n",
      "model.layers.30.post_attention_layernorm\n",
      "model.layers.31\n",
      "model.layers.31.self_attn\n",
      "model.layers.31.self_attn.q_proj\n",
      "model.layers.31.self_attn.k_proj\n",
      "model.layers.31.self_attn.v_proj\n",
      "model.layers.31.self_attn.o_proj\n",
      "model.layers.31.self_attn.rotary_emb\n",
      "model.layers.31.mlp\n",
      "model.layers.31.mlp.gate_proj\n",
      "model.layers.31.mlp.up_proj\n",
      "model.layers.31.mlp.down_proj\n",
      "model.layers.31.mlp.act_fn\n",
      "model.layers.31.input_layernorm\n",
      "model.layers.31.post_attention_layernorm\n",
      "model.norm\n",
      "model.rotary_emb\n",
      "score\n"
     ]
    }
   ],
   "source": [
    "for name, module in llama_model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68bd669f-2069-4fc9-baf2-6c15e2542698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "def get_lora_target_modules(model):\n",
    "    target_modules = set()\n",
    "    for name, module in model.named_modules():\n",
    "        # Check if the module is of a supported type\n",
    "        if isinstance(module, (torch.nn.Linear, torch.nn.Embedding, torch.nn.Conv2d, transformers.pytorch_utils.Conv1D)):\n",
    "            # Exclude containers like ModuleDict\n",
    "            if not isinstance(module, torch.nn.ModuleDict):\n",
    "                # Check for common attention layer names in the module name\n",
    "                if any(key in name.lower() for key in ['q_proj', 'k_proj', 'v_proj', 'out_proj', 'c_attn', 'c_proj', 'fc1', 'fc2', 'wte']):\n",
    "                    target_modules.add(name)\n",
    "    return list(target_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daac32f3-b20e-49c2-b225-7c0fed228cf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 Target Modules: ['transformer.h.0.mlp.c_proj', 'transformer.h.7.attn.c_proj', 'transformer.h.3.attn.c_attn', 'transformer.h.1.attn.c_proj', 'transformer.h.11.attn.c_attn', 'transformer.h.7.mlp.c_proj', 'transformer.h.10.attn.c_attn', 'transformer.h.5.mlp.c_proj', 'transformer.h.6.attn.c_proj', 'transformer.h.6.attn.c_attn', 'transformer.h.1.mlp.c_proj', 'transformer.h.2.mlp.c_proj', 'transformer.h.11.attn.c_proj', 'transformer.h.8.attn.c_attn', 'transformer.h.2.attn.c_proj', 'transformer.h.8.mlp.c_proj', 'transformer.h.1.attn.c_attn', 'transformer.h.4.mlp.c_proj', 'transformer.h.5.attn.c_attn', 'transformer.h.0.attn.c_attn', 'transformer.h.6.mlp.c_proj', 'transformer.h.2.attn.c_attn', 'transformer.h.11.mlp.c_proj', 'transformer.h.4.attn.c_attn', 'transformer.wte', 'transformer.h.0.attn.c_proj', 'transformer.h.10.attn.c_proj', 'transformer.h.9.attn.c_attn', 'transformer.h.10.mlp.c_proj', 'transformer.h.7.attn.c_attn', 'transformer.h.9.mlp.c_proj', 'transformer.h.4.attn.c_proj', 'transformer.h.3.mlp.c_proj', 'transformer.h.5.attn.c_proj', 'transformer.h.9.attn.c_proj', 'transformer.h.3.attn.c_proj', 'transformer.h.8.attn.c_proj']\n",
      "LLaMA Target Modules: ['model.layers.13.self_attn.k_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.26.self_attn.q_proj', 'model.layers.28.self_attn.v_proj', 'model.layers.11.self_attn.q_proj', 'model.layers.30.self_attn.q_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.30.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.24.self_attn.v_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.27.self_attn.v_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.10.self_attn.q_proj', 'model.layers.1.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.28.self_attn.q_proj', 'model.layers.12.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.22.self_attn.q_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.31.self_attn.q_proj', 'model.layers.6.self_attn.q_proj', 'model.layers.2.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.17.self_attn.q_proj', 'model.layers.27.self_attn.q_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.9.self_attn.q_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.25.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.29.self_attn.v_proj', 'model.layers.29.self_attn.k_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.7.self_attn.q_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.4.self_attn.q_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.28.self_attn.k_proj', 'model.layers.19.self_attn.q_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.15.self_attn.q_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.30.self_attn.v_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.3.self_attn.q_proj', 'model.layers.16.self_attn.q_proj', 'model.layers.26.self_attn.v_proj', 'model.layers.31.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.27.self_attn.k_proj', 'model.layers.0.self_attn.q_proj', 'model.layers.31.self_attn.v_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.5.self_attn.q_proj', 'model.layers.20.self_attn.q_proj', 'model.layers.25.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.8.self_attn.q_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.29.self_attn.q_proj', 'model.layers.13.self_attn.q_proj', 'model.layers.14.self_attn.q_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.18.self_attn.q_proj', 'model.layers.21.self_attn.q_proj', 'model.layers.23.self_attn.q_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.24.self_attn.q_proj']\n"
     ]
    }
   ],
   "source": [
    "# Get target modules for GPT-2\n",
    "gpt_target_modules = get_lora_target_modules(gpt_model)\n",
    "print(\"GPT-2 Target Modules:\", gpt_target_modules)\n",
    "\n",
    "# Get target modules for LLaMA\n",
    "llama_target_modules = get_lora_target_modules(llama_model)\n",
    "print(\"LLaMA Target Modules:\", llama_target_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b84217d3-1a02-4e1d-b40e-5ac6376f3a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/peft/tuners/lora/layer.py:1150: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# LoRA configuration for GPT-2\n",
    "lora_config_gpt = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=gpt_target_modules\n",
    ")\n",
    "\n",
    "# LoRA configuration for LLaMA\n",
    "lora_config_llama = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=llama_target_modules\n",
    ")\n",
    "\n",
    "\n",
    "gpt_model = get_peft_model(gpt_model, lora_config_gpt)\n",
    "llama_model = get_peft_model(llama_model, lora_config_llama)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8afeba-b459-4541-8ff3-582df2247267",
   "metadata": {},
   "source": [
    "### Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00ae2f67-95d0-4060-92e6-25404179f4b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d47227466d42568ec53b9cb4a6aab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd53b94d16f4db68bd4c2865f9f30e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt_2_tokenized_ds: {'train': Dataset({\n",
      "    features: ['style', 'text', 'category', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 1000\n",
      "}), 'test': Dataset({\n",
      "    features: ['style', 'text', 'category', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 1000\n",
      "})}\n",
      "llama_tokenized_ds: {'train': Dataset({\n",
      "    features: ['style', 'text', 'category', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 1000\n",
      "}), 'test': Dataset({\n",
      "    features: ['style', 'text', 'category', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 1000\n",
      "})}\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_function(examples, tokenizer, return_tensors=False):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",  # Ensure padding is applied\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\" if return_tensors else None\n",
    "    )\n",
    "    # Ensure labels are integers\n",
    "    if \"style\" in examples:\n",
    "        tokenized_inputs[\"labels\"] = [label2id[label] for label in examples[\"style\"]]\n",
    "        \n",
    "    return tokenized_inputs\n",
    "\n",
    "gpt_2_tokenize = partial(preprocess_function, tokenizer=gpt_tokenizer)\n",
    "llama_tokenize = partial(preprocess_function, tokenizer=llama_tokenizer)\n",
    "\n",
    "def tokenize_splits(model_tokenizer):\n",
    "    tokenized_datasets = {}\n",
    "    for split in ds.keys():\n",
    "        # Tokenize the split\n",
    "        tokenized_split = ds[split].map(model_tokenizer, batched=True)\n",
    "        \n",
    "        # Rename the 'label' column to 'labels'\n",
    "        # tokenized_split = tokenized_split.rename_column(\"style\", \"labels\")\n",
    "        \n",
    "        # Set the format of the dataset to PyTorch tensors\n",
    "        tokenized_split.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "        \n",
    "        # Store the processed split\n",
    "        tokenized_datasets[split] = tokenized_split\n",
    "\n",
    "    return tokenized_datasets\n",
    "        \n",
    "gpt_2_tokenized_ds = tokenize_splits(gpt_2_tokenize)\n",
    "llama_tokenized_ds = tokenize_splits(llama_tokenize)\n",
    "print(f\"gpt_2_tokenized_ds: {gpt_2_tokenized_ds}\")\n",
    "print(f\"llama_tokenized_ds: {llama_tokenized_ds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed63459-3712-44de-aea5-8fd623064d8b",
   "metadata": {},
   "source": [
    "## Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "684399e7-a081-4a8e-8d10-f1936e62e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "def generate_training_args(model_save_name):\n",
    "    return TrainingArguments(\n",
    "    output_dir=f\"./results/{model_save_name}\",\n",
    "    overwrite_output_dir=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=1,\n",
    "    dataloader_num_workers=4,\n",
    "    dataloader_pin_memory=True,\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "# Use the evaluate library for metrics\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    # Ensure logits and labels are on CPU and converted to numpy arrays\n",
    "    if isinstance(logits, torch.Tensor):\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    precision = precision_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "    return {\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "        \"precision\": precision[\"precision\"],\n",
    "        \"recall\": recall[\"recall\"],\n",
    "        \"f1\": f1[\"f1\"],\n",
    "    }\n",
    "\n",
    "# Create validation split function\n",
    "def create_validation_split(dataset_dict):\n",
    "    # Check if 'train' split exists\n",
    "    if 'train' in dataset_dict:\n",
    "        # Perform train_test_split on the 'train' dataset\n",
    "        split_dataset = dataset_dict['train'].train_test_split(test_size=0.1)\n",
    "        # Update the dataset dictionary\n",
    "        dataset_dict['train'] = split_dataset['train']\n",
    "        dataset_dict['validation'] = split_dataset['test']\n",
    "    else:\n",
    "        raise ValueError(\"No 'train' split found in the dataset.\")\n",
    "    return dataset_dict\n",
    "\n",
    "gpt_data_collator = DataCollatorWithPadding(tokenizer=gpt_tokenizer)\n",
    "llama_data_collator = DataCollatorWithPadding(tokenizer=llama_tokenizer)\n",
    "\n",
    "# Assuming gpt_2_tokenized_ds is your dataset\n",
    "gpt_2_tokenized_ds = create_validation_split(gpt_2_tokenized_ds)\n",
    "gpt_trainer = Trainer(\n",
    "    model=gpt_model,\n",
    "    args=generate_training_args(\"gpt_model\"),\n",
    "    train_dataset=gpt_2_tokenized_ds[\"train\"],\n",
    "    eval_dataset=gpt_2_tokenized_ds[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=gpt_data_collator,\n",
    ")\n",
    "\n",
    "# Repeat for LLaMA dataset and trainer\n",
    "llama_tokenized_ds = create_validation_split(llama_tokenized_ds)\n",
    "llama_trainer = Trainer(\n",
    "    model=llama_model,\n",
    "    args=generate_training_args(\"llama_model\"),\n",
    "    train_dataset=llama_tokenized_ds[\"train\"],\n",
    "    eval_dataset=llama_tokenized_ds[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=llama_data_collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c715a9e0-4e44-4ec7-bfe0-c3e297681b0a",
   "metadata": {},
   "source": [
    "### Train GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f0b88da-e460-42d0-9d16-47cd5a208eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [135/135 11:10, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.351000</td>\n",
       "      <td>4.502582</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.058118</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.006415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.725600</td>\n",
       "      <td>2.606043</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.214295</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.106083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.334200</td>\n",
       "      <td>2.398203</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.242752</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.202293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/Users/david/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/Users/david/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/Users/david/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=135, training_loss=4.216183683607313, metrics={'train_runtime': 683.0957, 'train_samples_per_second': 3.202, 'train_steps_per_second': 0.198, 'total_flos': 572093351411712.0, 'train_loss': 4.216183683607313, 'epoch': 2.958904109589041})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c4cb151-2efd-4e25-beba-9f7d714d79be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 01:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.4646122455596924,\n",
       " 'eval_accuracy': 0.266,\n",
       " 'eval_precision': 0.15258271550766495,\n",
       " 'eval_recall': 0.266,\n",
       " 'eval_f1': 0.16977673070328198,\n",
       " 'eval_runtime': 82.7162,\n",
       " 'eval_samples_per_second': 12.09,\n",
       " 'eval_steps_per_second': 6.045,\n",
       " 'epoch': 2.986666666666667}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be456047-17a9-4e5d-b3b4-32fb48a1665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_trainer.save_model(\"./results/gpt_model\")  \n",
    "gpt_tokenizer.save_pretrained(\"./results/gpt_model\") \n",
    "gpt_model.config.save_pretrained(\"./results/gpt_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aee62591-2a77-4487-b153-21df1232fbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Load the tokenizer\n",
    "gpt_tokenizer_loaded = AutoTokenizer.from_pretrained('./results/gpt_model')\n",
    "gpt_model_loaded = AutoModelForSequenceClassification.from_pretrained(\n",
    "    './results/gpt_model',\n",
    "    num_labels=14  # Ensure this matches the number of labels used during training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b1d005f-e90c-43bc-b281-84a8ae3e155f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'style': 'woolf',\n",
       " 'text': '\"It\\'s his way of making friends, I suppose,\" she laughed. \"Well--I shall do my part. I shall begin--\\'Ugly in body, repulsive in mind as you are, Mr. Hirst--\\'\"',\n",
       " 'category': 'author'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['test'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b46dc9c-fd18-4d07-bdf2-712c53e3d333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([5])\n"
     ]
    }
   ],
   "source": [
    "# Pass the 'text' directly to get_prediction\n",
    "input_text = ds['test'][15]['text']\n",
    "\n",
    "# Get the prediction\n",
    "predicted_class = get_prediction(gpt_model_loaded, input_text, gpt_tokenizer_loaded)\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8885b4f4-fd98-4121-b137-b91a5f692256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(ds, model=gpt_model_loaded, tokenizer=gpt_tokenizer_loaded, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123157dd-5ab4-4b3b-bfc0-4b222e1e8253",
   "metadata": {},
   "source": [
    "### Llama Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "986c64b8-0a85-47fa-9ac5-ca3e74742f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/168 : < :, Epoch 0.02/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llama_trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1939\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1940\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1941\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   1942\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1943\u001b[0m     )\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/transformers/trainer.py:2279\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2279\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2282\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2283\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2284\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2285\u001b[0m ):\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2287\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/transformers/trainer.py:3349\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3347\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/accelerate/accelerator.py:2196\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2196\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    527\u001b[0m )\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[1;32m    268\u001b[0m     tensors,\n\u001b[1;32m    269\u001b[0m     grad_tensors_,\n\u001b[1;32m    270\u001b[0m     retain_graph,\n\u001b[1;32m    271\u001b[0m     create_graph,\n\u001b[1;32m    272\u001b[0m     inputs,\n\u001b[1;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m )\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "llama_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffcd161-49e1-4084-90d6-3709787383e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
