{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd1e6a2a-c537-448d-b2b3-9a0d725f93d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b0c443-c53e-4ab5-880b-2f5426536e0a",
   "metadata": {},
   "source": [
    "Below I list the PEFT technique, the model, evaluation approach and fine-tunning dataset I'll be using to fine tune the LLM\n",
    "* PEFT technique: LoRA\n",
    "* Model: Llama 3.1 8B\n",
    "* Evaluation approach: Hugging Face Trainer.evaluate\n",
    "* Fine-tuning dataset: [AuthorMix](https://huggingface.co/datasets/hallisky/AuthorMix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a20aa8-1dda-4a38-a501-7b06fb61ed8d",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "Loading Llama 3.1 8B model and evaluate its performance prior to fine-tuning. This includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58143446-4483-4e1f-9e55-c54d719d01da",
   "metadata": {},
   "source": [
    "## Load in IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd388f79-cce5-4539-814d-10efe4a018cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q \"datasets>=2.16.1\"\n",
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install python-dotenv\n",
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8918ad8a-b8de-4a6c-87c6-1a2ad236fbba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['style', 'text', 'category'],\n",
       "     num_rows: 1000\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['style', 'text', 'category'],\n",
       "     num_rows: 1000\n",
       " })}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the train and test splits of the imdb dataset\n",
    "splits = [\"train\", \"test\"]\n",
    "ds = {\n",
    "    split: ds for split,\n",
    "    ds in zip(splits, load_dataset(\"hallisky/AuthorMix\", split=splits))\n",
    "}\n",
    "\n",
    "# Thin out the dataset to make it run faster for this example\n",
    "for split in splits:\n",
    "    ds[split] = ds[split].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "# Show the dataset\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6856202-59c2-455e-95ce-3f20ec749bde",
   "metadata": {},
   "source": [
    "### Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b0c14d-6f47-4031-ab63-f4b680484d44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       style                                               text category\n",
      "0  blog11518  \"Jamaia....come and help me talk some sense in...     blog\n",
      "1  blog25872  I decided I wasn't going to go to Boler today....     blog\n",
      "2      obama  For over two decades, bin Laden has been al Qa...   speech\n",
      "3  blog11518  motion with precise timing. Sucking the cigare...     blog\n",
      "4  blog11518  \"So what, we just stand here?\" Alyx prompts, h...     blog\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame(ds['train'])\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b723df4a-f77c-481f-a4c3-46aab12ee804",
   "metadata": {},
   "source": [
    "The dataset contains 14 unique authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55da3da0-d383-4102-a38c-3d642689d940",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blog11518' 'blog25872' 'obama' 'fitzgerald' 'hemingway' 'woolf' 'bush'\n",
      " 'blog30102' 'blog5546' 'trump' 'blog30407' 'qq' 'pp' 'h']\n"
     ]
    }
   ],
   "source": [
    "unique_styles = train_df['style'].unique()\n",
    "print(unique_styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a140e13c-516d-49c6-b1be-2cc84f858800",
   "metadata": {},
   "source": [
    "In 4 number of formats/categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "099a092b-1450-4499-a5c8-345a5b40c8c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blog' 'speech' 'author' 'amt']\n"
     ]
    }
   ],
   "source": [
    "unique_formats = train_df['category'].unique()\n",
    "print(unique_formats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9d27df-5594-4981-b4bc-e13cb280c6b8",
   "metadata": {},
   "source": [
    "Dataset sample text length just skew towards 335 characters or less "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a869c4b-ac04-40f6-9e0e-4c4a89d805fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_df['text_length'] = train_df['text'].str.len()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train_df['text_length'], bins=30, edgecolor='black')\n",
    "plt.title('Distribution of Text Lengths')\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eafac08-a712-4ede-b84b-d4e16b473877",
   "metadata": {},
   "source": [
    "### Intial Llama 3.1 8B/GPT-2 evaluation on the dataset\n",
    "Going to load in the Llama/GPT-2 model through AutoModelForSequenceClassification and set the label ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8363fe2a-97b2-43eb-9dcb-8430e7cab142",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/david/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv(\"env.txt\")\n",
    "hf_token = os.getenv('HF_API_TOKEN')\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "945e0a85-1e77-4f16-9e5b-439d558fd8ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_labels: 14\n",
      "id2label: {0: 'blog11518', 1: 'blog25872', 2: 'obama', 3: 'fitzgerald', 4: 'hemingway', 5: 'woolf', 6: 'bush', 7: 'blog30102', 8: 'blog5546', 9: 'trump', 10: 'blog30407', 11: 'qq', 12: 'pp', 13: 'h'}\n",
      "label2id: {'blog11518': 0, 'blog25872': 1, 'obama': 2, 'fitzgerald': 3, 'hemingway': 4, 'woolf': 5, 'bush': 6, 'blog30102': 7, 'blog5546': 8, 'trump': 9, 'blog30407': 10, 'qq': 11, 'pp': 12, 'h': 13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcd9c494afa4f4bb71173f208148c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3.1-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "num_labels = len(unique_styles)\n",
    "id2label = {i: style for i, style in enumerate(unique_styles)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "print(f\"num_labels: {num_labels}\")\n",
    "print(f\"id2label: {id2label}\")\n",
    "print(f\"label2id: {label2id}\")\n",
    "llama_model_key = \"meta-llama/Meta-Llama-3.1-8B\"\n",
    "gpt_model_key = \"openai-community/gpt2\"\n",
    "gpt_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    gpt_model_key,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    token=True,\n",
    ")\n",
    "llama_model = gpt_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    llama_model_key,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    token=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0984e7e6-b9b3-46b5-8f86-570d30b4ef89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer setup\n",
    "# GPT\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained(gpt_model_key, token=True)\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "#llama\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(llama_model_key, token=True)\n",
    "llama_tokenizer.pad_token = llama_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "653edbc2-728f-46d5-9d14-8b3c03fe1d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text, model, tokenizer):\n",
    "\n",
    "    # Tokenize the text\n",
    "    # (Get the response as tensors and not as a list)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Perform the prediction (get the logits)\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Get the logits\n",
    "    logits = outputs.logits\n",
    "    \n",
    "    # Apply softmax to the logits to get probabilities\n",
    "    probabilities = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "    # Get the predicted class (corresponding to the highest logit)\n",
    "    predicted_class = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    return predicted_class, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0dcbdde-f0b5-4f01-862b-21818900e8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'style': 'woolf',\n",
       " 'text': '\"It\\'s his way of making friends, I suppose,\" she laughed. \"Well--I shall do my part. I shall begin--\\'Ugly in body, repulsive in mind as you are, Mr. Hirst--\\'\"',\n",
       " 'category': 'author'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['test'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f05ebc89-7a46-44e5-baca-65bdddd2da19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7]),\n",
       " tensor([[3.6282e-03, 2.8605e-05, 4.9584e-06, 1.0194e-06, 2.3843e-03, 3.9152e-04,\n",
       "          8.7304e-04, 9.8857e-01, 2.6047e-03, 1.4705e-03, 4.7815e-05]],\n",
       "        grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = get_prediction(ds['test'][15]['text'], llama_model, llama_tokenizer)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c78c3b88-9a09-4331-a2a1-051cbb091a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def evaluate_model(dataset, model, tokenizer, n=None):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # If n is None, evaluate the whole dataset\n",
    "    n = len(dataset['test']) if n is None else n\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Loop over the dataset up to n rows\n",
    "    for i in range(n):\n",
    "        # Get the input text and true label from the dataset\n",
    "        text = dataset['test'][i]['text']\n",
    "        true_label = dataset['test'][i]['style']  # Assuming 'style' is the label field\n",
    "        \n",
    "        # Get the model's prediction and probabilities\n",
    "        predicted_class, _ = get_prediction(text, model, tokenizer)\n",
    "        \n",
    "        # Check if the prediction is correct\n",
    "        if predicted_class.item() == label2id[true_label]:  # Convert tensor to scalar with .item()\n",
    "            correct_predictions += 1\n",
    "        \n",
    "        total_predictions += 1\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    accuracy = correct_predictions / total_predictions * 100\n",
    "    print(f\"Accuracy: {accuracy:.2f}% ({correct_predictions}/{total_predictions})\")\n",
    "    print(f\"Time taken: {time_taken:.2f} seconds for {n} samples\")\n",
    "\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32218169-b5d1-4511-a8be-0e2e2a1093db",
   "metadata": {},
   "source": [
    "### Llama Pre-Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e4677df-46c5-420f-b436-4bcb2dbc5d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00% (0/10)\n",
      "Time taken: 284.47 seconds for 10 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(ds, model=llama_model, tokenizer=llama_tokenizer, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c653f8-d751-4274-afd3-c8c86e5caca0",
   "metadata": {},
   "source": [
    "### GPT Pre-Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cc73d4d-2a3b-4c3d-8786-f59a83499447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00% (0/10)\n",
      "Time taken: 280.59 seconds for 10 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(ds, model=gpt_model, tokenizer=gpt_tokenizer, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b02d83d-3cf8-4e4d-b21b-579897320b93",
   "metadata": {},
   "source": [
    "### Setup PEFT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b84217d3-1a02-4e1d-b40e-5ac6376f3a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Set up LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "\n",
    "gpt_model = get_peft_model(gpt_model, lora_config)\n",
    "llama_model = get_peft_model(llama_model, lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8afeba-b459-4541-8ff3-582df2247267",
   "metadata": {},
   "source": [
    "### Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00ae2f67-95d0-4060-92e6-25404179f4b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001ea74482d749a79fd7bc6a2e137031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1104f4f4874acd8c804024d1a7c424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt_2_tokenized_ds: {'train': Dataset({\n",
      "    features: ['labels', 'text', 'category', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 1000\n",
      "}), 'test': Dataset({\n",
      "    features: ['labels', 'text', 'category', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 1000\n",
      "})}\n",
      "llama_tokenized_ds: {'train': Dataset({\n",
      "    features: ['labels', 'text', 'category', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 1000\n",
      "}), 'test': Dataset({\n",
      "    features: ['labels', 'text', 'category', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 1000\n",
      "})}\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_function(examples, tokenizer):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=1600) #longest character count in dataset is about 1,550 characters, hints the max length\n",
    "    # tokens['label'] = [label2id.get(style, -1) for style in examples['style']]\n",
    "    # return tokens\n",
    "\n",
    "gpt_2_tokenize = partial(preprocess_function, tokenizer=gpt_tokenizer)\n",
    "llama_tokenize = partial(preprocess_function, tokenizer=llama_tokenizer)\n",
    "\n",
    "def tokenize_splits(model_tokenizer):\n",
    "    tokenized_datasets = {}\n",
    "    for split in ds.keys():\n",
    "        # Tokenize the split\n",
    "        tokenized_split = ds[split].map(model_tokenizer, batched=True)\n",
    "        \n",
    "        # Rename the 'label' column to 'labels'\n",
    "        tokenized_split = tokenized_split.rename_column(\"style\", \"labels\")\n",
    "        \n",
    "        # Set the format of the dataset to PyTorch tensors\n",
    "        tokenized_split.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "        \n",
    "        # Store the processed split\n",
    "        tokenized_datasets[split] = tokenized_split\n",
    "\n",
    "    return tokenized_datasets\n",
    "        \n",
    "gpt_2_tokenized_ds = tokenize_splits(gpt_2_tokenize)\n",
    "llama_tokenized_ds = tokenize_splits(llama_tokenize)\n",
    "print(f\"gpt_2_tokenized_ds: {gpt_2_tokenized_ds}\")\n",
    "print(f\"llama_tokenized_ds: {llama_tokenized_ds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed63459-3712-44de-aea5-8fd623064d8b",
   "metadata": {},
   "source": [
    "## Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "684399e7-a081-4a8e-8d10-f1936e62e65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/Users/david/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/Users/david/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/datasets/load.py:759: FutureWarning: The repository for precision contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/precision/precision.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/Users/david/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/datasets/load.py:759: FutureWarning: The repository for recall contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/recall/recall.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/Users/david/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/datasets/load.py:759: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from datasets import load_metric\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=1\n",
    ")\n",
    "\n",
    "# Define metrics\n",
    "accuracy_metric = load_metric(\"accuracy\")\n",
    "precision_metric = load_metric(\"precision\")\n",
    "recall_metric = load_metric(\"recall\")\n",
    "f1_metric = load_metric(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    precision = precision_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "    return {\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "        \"precision\": precision[\"precision\"],\n",
    "        \"recall\": recall[\"recall\"],\n",
    "        \"f1\": f1[\"f1\"],\n",
    "    }\n",
    "\n",
    "\n",
    "##setup validation for datasets\n",
    "def create_validation_split(dataset):\n",
    "    dataset[\"train\"] = dataset[\"train\"].train_test_split(test_size=0.1)\n",
    "    dataset[\"validation\"] = dataset[\"train\"][\"test\"]\n",
    "    dataset[\"train\"] = dataset[\"train\"][\"train\"]\n",
    "    return dataset\n",
    "\n",
    "gpt_2_tokenized_ds = create_validation_split(gpt_2_tokenized_ds)\n",
    "gpt_trainer = Trainer(\n",
    "    model=gpt_model,\n",
    "    args=training_args,\n",
    "    train_dataset=gpt_2_tokenized_ds[\"train\"],\n",
    "    eval_dataset=gpt_2_tokenized_ds[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "llama_tokenized_ds = create_validation_split(llama_tokenized_ds)\n",
    "llama_trainer = Trainer(\n",
    "    model=llama_model,\n",
    "    args=training_args,\n",
    "    train_dataset=llama_tokenized_ds[\"train\"],\n",
    "    eval_dataset=llama_tokenized_ds[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c715a9e0-4e44-4ec7-bfe0-c3e297681b0a",
   "metadata": {},
   "source": [
    "### Train GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f0b88da-e460-42d0-9d16-47cd5a208eb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 45.64 GB, other allocations: 210.75 MB, max allowed: 45.90 GB). Tried to allocate 200.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gpt_trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1939\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1940\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1941\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   1942\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1943\u001b[0m     )\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/transformers/trainer.py:2279\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2279\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2282\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2283\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2284\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2285\u001b[0m ):\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2287\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/transformers/trainer.py:3318\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3317\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3318\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)\n\u001b[1;32m   3320\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3323\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3324\u001b[0m ):\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/transformers/trainer.py:3363\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3362\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3363\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m   3364\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3365\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/peft/peft_model.py:1446\u001b[0m, in \u001b[0;36mPeftModelForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m peft_config\u001b[38;5;241m.\u001b[39mpeft_type \u001b[38;5;241m==\u001b[39m PeftType\u001b[38;5;241m.\u001b[39mPOLY:\n\u001b[1;32m   1445\u001b[0m             kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task_ids\n\u001b[0;32m-> 1446\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model(\n\u001b[1;32m   1447\u001b[0m             input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1448\u001b[0m             attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1449\u001b[0m             inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1450\u001b[0m             labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   1451\u001b[0m             output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1452\u001b[0m             output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1453\u001b[0m             return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1454\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1455\u001b[0m         )\n\u001b[1;32m   1457\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1459\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:197\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:1360\u001b[0m, in \u001b[0;36mLlamaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1358\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1360\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1361\u001b[0m     input_ids,\n\u001b[1;32m   1362\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1363\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1364\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1365\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1366\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1367\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1368\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1369\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1370\u001b[0m )\n\u001b[1;32m   1371\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1372\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore(hidden_states)\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:1001\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    989\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    990\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    991\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    998\u001b[0m         position_embeddings,\n\u001b[1;32m    999\u001b[0m     )\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1001\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[1;32m   1002\u001b[0m         hidden_states,\n\u001b[1;32m   1003\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask,\n\u001b[1;32m   1004\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1005\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1006\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1007\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1008\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m   1009\u001b[0m         position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[1;32m   1010\u001b[0m     )\n\u001b[1;32m   1012\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:734\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    733\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    735\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    736\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    737\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m    738\u001b[0m     past_key_value\u001b[38;5;241m=\u001b[39mpast_key_value,\n\u001b[1;32m    739\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    740\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    741\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m    742\u001b[0m     position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    744\u001b[0m )\n\u001b[1;32m    745\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:617\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m    605\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    606\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m         position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[1;32m    613\u001b[0m     )\n\u001b[1;32m    615\u001b[0m bsz, q_len, _ \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m--> 617\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj(hidden_states)\n\u001b[1;32m    618\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\n\u001b[1;32m    619\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/peft/tuners/lora/layer.py:584\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    581\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(lora_A\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dora[active_adapter]:\n\u001b[0;32m--> 584\u001b[0m     result \u001b[38;5;241m=\u001b[39m result \u001b[38;5;241m+\u001b[39m lora_B(lora_A(dropout(x))) \u001b[38;5;241m*\u001b[39m scaling\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    586\u001b[0m     x \u001b[38;5;241m=\u001b[39m dropout(x)\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Personal/Personal-Learning/foundational-modal-tuning/env/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 45.64 GB, other allocations: 210.75 MB, max allowed: 45.90 GB). Tried to allocate 200.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "gpt_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4cb151-2efd-4e25-beba-9f7d714d79be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
